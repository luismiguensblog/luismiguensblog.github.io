<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Parallel on Luis Miguens Blog</title>
    <link>https://blog.miguens.one/tags/parallel/</link>
    <description>Recent content in Parallel on Luis Miguens Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 24 Mar 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://blog.miguens.one/tags/parallel/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parallelism in Python: Linux vs Windows.</title>
      <link>https://blog.miguens.one/posts/2021/03/parallelism-in-python-linux-vs-windows./</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2021/03/parallelism-in-python-linux-vs-windows./</guid>
      <description>&lt;p&gt;In Linux, when you start a child process, it is &lt;strong&gt;Forked&lt;/strong&gt;. It means that the child process inherits the memory state of the parent process. On Windows (and by default on Mac), however, processes are &lt;strong&gt;Spawned&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Even though processes usually speed up the execution of a program by using multiple cores on a computer, starting each process can be time-consuming.&lt;/p&gt;&#xA;&lt;p&gt;The fact that on Windows and Mac Python needs to &lt;em&gt;pickle&lt;/em&gt; the objects to create child processes adds an overhead that may offset the benefits of running on separated processes. It is especially relevant when you have many small tasks to perform, instead of a couple of long-running ones.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parallelism in Python.</title>
      <link>https://blog.miguens.one/posts/2021/03/parallelism-in-python./</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2021/03/parallelism-in-python./</guid>
      <description>&lt;p&gt;In Python, &lt;strong&gt;by default&lt;/strong&gt; we have three options to add parallel processing to our applications:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;threading&lt;/li&gt;&#xA;&lt;li&gt;multiprocessing&lt;/li&gt;&#xA;&lt;li&gt;concurrent.futures&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The first option, &lt;code&gt;threading&lt;/code&gt; is useful with I/O and networking tasks, as the parallelization remains in a single core.&lt;/p&gt;&#xA;&lt;p&gt;The second option, &lt;code&gt;multiprocessing&lt;/code&gt;, is used with intensive CPU tasks, and the processing will be distributed in all the cores of our machine. The disadvantage of &lt;code&gt;multiprocessing&lt;/code&gt; is that all the information and objects should be serializable. To know is an object is serializable, you can try to &lt;code&gt;pickle&lt;/code&gt; and &lt;code&gt;unpickle&lt;/code&gt;. If the process goes without error, you can use  &lt;code&gt;multiprocessing&lt;/code&gt; as a rule of the tumb.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
