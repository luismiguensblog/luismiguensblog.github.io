<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Devops on Luis Miguens Blog</title>
    <link>https://blog.miguens.one/tags/devops/</link>
    <description>Recent content in Devops on Luis Miguens Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 07 Aug 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://blog.miguens.one/tags/devops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Increase the Speed of GitLab Pipelines</title>
      <link>https://blog.miguens.one/posts/2023/08/how-to-increase-the-speed-of-gitlab-pipelines/</link>
      <pubDate>Mon, 07 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/08/how-to-increase-the-speed-of-gitlab-pipelines/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;GitLab is a comprehensive DevOps platform that provides a seamless environment for developers to create, test, and deploy code. GitLab CI/CD (Continuous Integration/Continuous Deployment) pipelines are an essential feature that enables teams to automate the build, test, and deployment processes. However, as projects grow in size and complexity, pipeline execution can slow down, impacting overall productivity. This article outlines strategies to increase the speed of your GitLab pipelines, ensuring an efficient software development process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Perils of Using a Distributed Cache for GitLab Runners</title>
      <link>https://blog.miguens.one/posts/2023/07/the-perils-of-using-a-distributed-cache-for-gitlab-runners/</link>
      <pubDate>Sun, 30 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/07/the-perils-of-using-a-distributed-cache-for-gitlab-runners/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;p&gt;GitLab is a popular platform for developers to manage their software development lifecycle, including source code management, continuous integration, and continuous deployment. With GitLab Runners, teams can run their CI/CD pipelines to automate the build, test, and deployment process. But when it comes to optimizing pipeline performance, there&amp;rsquo;s a popular misconception that using a distributed cache for GitLab Runners is a good idea. In this article, we will discuss why implementing a distributed cache for GitLab Runners can actually be detrimental to your pipeline, and we will offer alternative solutions for exchanging data between jobs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Mutexes and Multithreading in C</title>
      <link>https://blog.miguens.one/posts/2023/06/an-introduction-to-mutexes-and-multithreading-in-c/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/06/an-introduction-to-mutexes-and-multithreading-in-c/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Title: An Introduction to Mutexes and Multithreading in C&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In the world of programming, threads are a crucial concept that allows for concurrent execution within a single process. This concurrent execution is made possible through multithreading, a widespread technique in modern programming. However, when multiple threads access a shared resource, synchronization problems can arise. In this blog post, we&amp;rsquo;ll explore how to use Mutexes in C for thread synchronization and delve into the concept of multithreading.&lt;/p&gt;</description>
    </item>
    <item>
      <title>High-performance runners on GitLab CI</title>
      <link>https://blog.miguens.one/posts/2023/06/high-performance-runners-on-gitlab-ci/</link>
      <pubDate>Sun, 18 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/06/high-performance-runners-on-gitlab-ci/</guid>
      <description>&lt;p&gt;To ensure that high-performance runners are never idle while there are pending jobs, you can leverage the following strategies:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Runner priority (Enterprise Edition only): GitLab Enterprise Edition (Premium and Ultimate) offers the option to set runner priority directly in the Runner&amp;rsquo;s settings. You can give your high-performance runners a higher priority, which will make them pick jobs before low-performance runners. To set priority, go to the Runner&amp;rsquo;s details page in the GitLab web interface, and set the &amp;ldquo;Priority&amp;rdquo; field accordingly. Note that this feature is not available in GitLab Community Edition (CE).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Creating a Virtual File System with FUSE and Python</title>
      <link>https://blog.miguens.one/posts/2023/05/creating-a-virtual-file-system-with-fuse-and-python/</link>
      <pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/05/creating-a-virtual-file-system-with-fuse-and-python/</guid>
      <description>&lt;p&gt;&lt;strong&gt;This is a continuation of my previous article:&lt;/strong&gt; &lt;em&gt;Save Snippets of Python code as single XML file&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;creating-a-virtual-file-system-with-fuse-and-python&#34;&gt;Creating a Virtual File System with FUSE and Python&lt;/h1&gt;&#xA;&lt;p&gt;FUSE (Filesystem in Userspace) is a software interface that allows user-level programs to create and manage file systems without requiring root privileges. This makes it possible to create custom file systems that can be mounted and accessed like regular file systems.&lt;/p&gt;&#xA;&lt;p&gt;In this article, we will create a virtual file system using FUSE and Python. The file system will expose a set of Python code snippets as files, allowing users to read and execute the snippets as if they were regular Python scripts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Save Snippets of Python code as single XML file</title>
      <link>https://blog.miguens.one/posts/2023/04/save-snippets-of-python-code-as-single-xml-file/</link>
      <pubDate>Sat, 29 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/04/save-snippets-of-python-code-as-single-xml-file/</guid>
      <description>&lt;h1 id=&#34;how-to-use-an-xml-file-to-store-multiple-portions-of-python-code&#34;&gt;How to Use an XML File to Store Multiple Portions of Python Code&lt;/h1&gt;&#xA;&lt;p&gt;Have you ever needed to run several Python code snippets in the cloud and wished for an easy way to organize and package them? One way to accomplish this is by using an XML file to store your Python code snippets. An XML file is a file format that is used to store and transport data, and can be easily read and written by machines. By creating an XML file to store your code snippets, you can easily package them together and upload them to the cloud to run as a single package.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speed Up I/O Performance with RAMDisk and LVM Cache</title>
      <link>https://blog.miguens.one/posts/2023/04/speed-up-i/o-performance-with-ramdisk-and-lvm-cache/</link>
      <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://blog.miguens.one/posts/2023/04/speed-up-i/o-performance-with-ramdisk-and-lvm-cache/</guid>
      <description>&lt;p&gt;In this blog article, we will discuss various methods to speed up I/O performance and ultimately settle on using LVM to mount a fast I/O device with a RAMDisk as cache. This approach is beneficial when you don&amp;rsquo;t care about retaining data in the location between reboots.&lt;/p&gt;&#xA;&lt;h2 id=&#34;options-considered&#34;&gt;Options Considered&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Only use RAM (i.e., tmpfs of 20 or 30GB)&lt;/strong&gt;: This option has the problem that if RAM is not enough, the build will fail.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use larger tmps (double the amounts above) and use the fast I/O location as a swap&lt;/strong&gt;: The issue with this option is that if the system needs to use the swap, the complete OS could become laggy and unresponsive, affecting the build times.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Concatenate RAM with Fast I/O using LVM&lt;/strong&gt;: This approach does not guarantee that the filesystem will write first on RAM.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use LVM to mount the Fast I/O with RAMDisk as cache&lt;/strong&gt;: This is the best approach among the options considered, but further research on the options of LVM is needed.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;We will focus on option 4 for the rest of this article.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
